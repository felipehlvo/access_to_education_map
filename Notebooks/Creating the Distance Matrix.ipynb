{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Distance Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to calculate the access metrics, we need a distance matrix of each supply point to each demand point. In our case, from the census tract centroid to each school. \n",
    "\n",
    "Calculating the distance between every single pair of supply and demand points is computationally inviable, so we define a threshold for a maximum distance and we split the calculation into chunks. In practice, we divide our dataframe based on the microregions of Brazil and calculate the distance matrix of each one separately. The benefit is that we don't have to check the distance for two points that are hundreds of miles away. The downside is that with this method we ignore that people can cross microregions to go to school. However, I consider that this scenario is extremely uncommon. \n",
    "\n",
    "We will use the [Haversine formula](https://en.wikipedia.org/wiki/Haversine_formula) to calculate the distance between two points on a sphere. The Haversine formula is a special case of the [Vincenty formula](https://en.wikipedia.org/wiki/Vincenty%27s_formulae), which is more accurate but also more computationally expensive. The Haversine formula is a good approximation for short distances, which is the case for our analysis.\n",
    "\n",
    "W="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "import warnings\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# importing basic dataset of the census tracts\n",
    "geo_school_census_df = pd.read_csv('/Users/feliphlvo/Documents/Minerva/Capstone/data/Local/school_census.csv', index_col=0)\n",
    "geo_dem_census_df = pd.read_csv('/Users/feliphlvo/Documents/Minerva/Capstone/data/Local/dem_census.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only public schools with at least one high school class and regions with at least one high-school aged person\n",
    "geo_dem_census_df = geo_dem_census_df[geo_dem_census_df[\"n_people_15to17\"] > 0]\n",
    "geo_school_census_df = geo_school_census_df[(geo_school_census_df[\"n_classes\"] > 0) & (geo_school_census_df[\"admin_type\"] != 4.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply geometries\n",
    "geo_dem_census_df = gpd.GeoDataFrame(geo_dem_census_df, geometry = geo_dem_census_df[\"geometry\"].apply(wkt.loads))\n",
    "geo_school_census_df = gpd.GeoDataFrame(geo_school_census_df, geometry = geo_school_census_df[\"geometry\"].apply(wkt.loads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "def distance_matrix(demand_df, supply_df, demand_index, supply_index, name = \"euclidean\", threshold = 10000):   \n",
    "    \"\"\"\"\"\n",
    "    This function calculates the distance matrix between every pair of points in two geodataframes up to a threshold.\n",
    "\n",
    "    Inspired by create_euclidean_distances in the Access package\n",
    "    \"\"\"\n",
    "\n",
    "    # Reset the index so that the geoids are accessible\n",
    "    df1 = demand_df.rename_axis(\"origin\").reset_index()\n",
    "    df2 = supply_df.rename_axis(\"dest\").reset_index()\n",
    "    \n",
    "    # Convert to centroids if so-specified\n",
    "    #print(df1.head())\n",
    "    df1.set_geometry(df1.centroid, inplace=True)\n",
    "    df2.set_geometry(df2.centroid, inplace=True)\n",
    "    # Calculate the distances.\n",
    "    if (df1.geom_type == \"Point\").all() & (df2.geom_type == \"Point\").all():\n",
    "        # If both geometries are point types, merge on a temporary dummy column\n",
    "        df1[\"temp\"] = 1\n",
    "        df2[\"temp\"] = 1\n",
    "        df1and2 = df1[[\"temp\", \"geometry\", \"origin\"]].merge(\n",
    "            df2[[\"temp\", \"geometry\", \"dest\"]].rename(columns={\"geometry\": \"geomb\"})\n",
    "        )\n",
    "        df1and2.drop(\"temp\", inplace=True, axis=1)\n",
    "        df1and2[name] = df1and2.distance(df1and2.set_geometry(\"geomb\"))\n",
    "    else:\n",
    "        # Execute an sjoin for non-point geometries, based upon a buffer zone\n",
    "        df1and2 = gpd.sjoin(\n",
    "            df1,\n",
    "            df2.rename(columns={\"geometry\": \"geomb\"}).set_geometry(\n",
    "                df2.buffer(threshold)\n",
    "            ),\n",
    "        )\n",
    "        df1and2[name] = df1and2.distance(df1and2.set_geometry(\"geomb\"))\n",
    "\n",
    "    # Add it to the cost df.\n",
    "    df1and2 = df1and2[df1and2[name] < threshold]\n",
    "    df1and2 = df1and2.reset_index()[[\"origin\", \"dest\", \"euclidean\"]]\n",
    "\n",
    "    return df1and2\n",
    "\n",
    "\n",
    "def chunked_distance_matrix(demand_df, supply_df, demand_index, supply_index, subset_column, name = \"euclidean\", threshold = 10000):\n",
    "    '''''\n",
    "    This function calculates the distance matrix between every pair of points in two geodataframes up to a threshold.\n",
    "    It calculates distances separately for each subset to avoid memory issues.\n",
    "    '''\n",
    "    demand_df = demand_df.copy()\n",
    "    supply_df = supply_df.copy()\n",
    "    \n",
    "    demand_df.set_index(demand_index, inplace=True)\n",
    "    supply_df.set_index(supply_index, inplace=True)\n",
    "\n",
    "    subset_values = demand_df[subset_column].unique()\n",
    "    # Initialize distance matrix df\n",
    "    distance_matrix_df = pd.DataFrame()\n",
    "    for value in tqdm(subset_values):\n",
    "        #print(\"Processing \" + str(value))\n",
    "        # Subset the dataframes\n",
    "        demand_subset = demand_df[demand_df[subset_column] == value]\n",
    "        supply_subset = supply_df[supply_df[subset_column] == value]\n",
    "        # Calculate the distance matrix\n",
    "        distance_matrix_df = distance_matrix_df.append(\n",
    "            distance_matrix(demand_subset, supply_subset,  demand_index, supply_index, name, threshold)\n",
    "        )\n",
    "    return distance_matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "geopandas.geodataframe.GeoDataFrame"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(geo_school_census_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [17:18<00:00,  7.53s/it]  \n"
     ]
    }
   ],
   "source": [
    "dist_matrix = chunked_distance_matrix(geo_dem_census_df, geo_school_census_df, demand_index=\"sector_id\",\n",
    "                                      supply_index=\"school_id\", subset_column=\"mesoregion_id\", name=\"euclidean\", threshold=16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin</th>\n",
       "      <th>dest</th>\n",
       "      <th>euclidean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.045708e+07</td>\n",
       "      <td>2.045708e+07</td>\n",
       "      <td>2.045708e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.380449e+14</td>\n",
       "      <td>3.371970e+07</td>\n",
       "      <td>9.523882e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.038906e+13</td>\n",
       "      <td>6.011901e+06</td>\n",
       "      <td>4.158382e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.100015e+14</td>\n",
       "      <td>1.100026e+07</td>\n",
       "      <td>1.499205e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.303203e+14</td>\n",
       "      <td>3.305547e+07</td>\n",
       "      <td>6.276567e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.539806e+14</td>\n",
       "      <td>3.500491e+07</td>\n",
       "      <td>9.949617e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.550309e+14</td>\n",
       "      <td>3.540532e+07</td>\n",
       "      <td>1.309348e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.300108e+14</td>\n",
       "      <td>5.306818e+07</td>\n",
       "      <td>1.600000e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             origin          dest     euclidean\n",
       "count  2.045708e+07  2.045708e+07  2.045708e+07\n",
       "mean   3.380449e+14  3.371970e+07  9.523882e+03\n",
       "std    6.038906e+13  6.011901e+06  4.158382e+03\n",
       "min    1.100015e+14  1.100026e+07  1.499205e+00\n",
       "25%    3.303203e+14  3.305547e+07  6.276567e+03\n",
       "50%    3.539806e+14  3.500491e+07  9.949617e+03\n",
       "75%    3.550309e+14  3.540532e+07  1.309348e+04\n",
       "max    5.300108e+14  5.306818e+07  1.600000e+04"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_matrix.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write distance matrix to csv\n",
    "dist_matrix.to_csv('/Users/feliphlvo/Documents/Minerva/Capstone/data/Local/dist_matrix.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('cap_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "998f53a967595206ca2b0fe694f898506950a27042b510ab2e2e2930595cb248"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
